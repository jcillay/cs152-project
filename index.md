<h1> 
  <b>Introduction</b> 
</h1>
  <p> 
Reinforcement learning has become one of the most prolific techniques within artificial intelligence. In our project, we will be taking advantage of this technique to teach an agent how to navigate a virtual maze with directional arrows using deep reinforcement learning. These directional arrows will be placed on the walls and will dictate which way for the agent to go to reach the final goal state – which is signified as a purple wall at the end of the maze. We chose to use deep reinforcement learning to solve this problem because it allows us to easily train our agent by breaking down the path towards our goal state into a series of moves that are signified as being either good (moving towards the goal state) or bad (moving away from the goal state). To accomplish this task, we will be using a variety of previous work done on the topic. Specifically, Dr. Anthony Clark’s research on the creation of the virtual maze and his existing program for it. To implement reinforcement learning on the existing program, we will use the toolkit known as OpenAI Gym – an open source toolkit that allows developers to implement different algorithms on the existing programs in certain environments. In our process of using OpenAI Gym we will be using the existing numerical computation library of either TensorFlow or Theano. 
</p>
<p>
 In addition to these resources, we will reference previous work done on related projects, such as, <a href="https://ieeexplore.ieee.org/abstract/document/8957297?casa_token=JTVW2Y0EiC0AAAAA:27v7m8lyZQv2Fzr_z1g_7siXz9q38bC3Y0o8gjPa3zc63nFnDR8AEF7hdET8vkxC8jyqhq8kPi0" >“Deep Reinforcement Learning for Instruction Following Visual Navigation in 3D Maze-like Environments”</a> (Devo, Costante, and Valigi, 2006), and <a href="https://magnus-engstrom.medium.com/building-an-ai-to-navigate-a-maze-899bf03f224d" >“Building an AI to Navigate a Maze”</a> (Engstrom, 2019). These projects will give us an idea of how to structure our algorithm and perform RL on our agent. Furthermore, we will use research articles like <a href="https://www.altexsoft.com/blog/datascience/reinforcement-learning-explained-overview-comparisons-and-applications-in-business/" >“Reinforcement Learning Explained: Overview, Comparisons and Applications in Business”</a> (altexsoft, 2019) and <a href="https://openreview.net/pdf?id=SJMGPrcle" >“Learning to Navigate in Complex Environments”</a> (Mirowski, 2017) to give us a deeper understanding of RL and navigation problems as a whole. Upon completion of our project, we may attempt to expand the scope of our project to include solving the maze without arrows, and even experiment with different virtual maze textures – if time allows. This project is being done with the hopes that it will contribute to the ultimate goal of Dr. Anthony Clark’s research, which is to have a robot be able to traverse and navigate Pomona College’s campus successfully and unharmed.
</p>
  
 <h1> Project progress </h1>
<ul>
  <li> 
  Currently in our project we are getting a feel for Dr. Clark's code and understanding reinforcement learning. We have downloaded the repository that contains the code and are in the process of understanding exactly how the program works. After meeting with Dr. Clark, we have decided that he will create the OpenAIGym environment for us and we will implement the code in that environment, since he is more familiar. In terms of an understanding of reinforcement learning, we are currently working through an introduction on the basics through this <a href="https://simoninithomas.github.io/deep-rl-course/">website</a>. We hope to apply this material to our project once the gym is has been created.
  </li>
  <li> 
  The only problems we have encountered so far have been an understanding of what exactly we need to accomplish in the project. 
  </li>
  <li> 
The grade we hope to receive on this project is an A. 
  </li>

</ul>
